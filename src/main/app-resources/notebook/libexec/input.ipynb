{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ewf-ext-03-02-01 - SeaEyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ewf-ext-03-02-01 - SeaEyes'),\n",
    "                ('abstract', 'ewf-ext-03-02-01 - SeaEyes'),\n",
    "                ('id', 'ewf-ext-03-02-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaptive Thresholding**\n",
    "\n",
    "Adaptive Thresholding: Extend the shoreline by this many pixels (Land-Sea-Mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shorelineExtension = dict([('id', 'shorelineExtension'),\n",
    "                           ('value', '10'),\n",
    "                           ('title', 'Shoreline Extension'),\n",
    "                           ('abstract', 'Shoreline Extension: Extend the shoreline by this many pixels (Land-Sea-Mask)'),\n",
    "                           ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability of false alarm**\n",
    "\n",
    "Probability of false alarm: The PFA value is computed by 10^(-x). where x is the given positive number (Adaptive Threshold Algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pfa = dict([('id', 'pfa'),\n",
    "            ('value', '12.5'),\n",
    "            ('title', 'Probability of false alarm'),\n",
    "            ('abstract', 'Probability of false alarm: The PFA value is computed by 10^(-x). where x is the given positive number (Adaptive Threshold Algorithm)'),\n",
    "            ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimum Target Size (m)**\n",
    "\n",
    "Minimum Target Size (m): Target with dimension smaller than this threshold is eliminated (Object-Discrimination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minTargetSizeInMeter = dict([('id', 'minTargetSizeInMeter'),\n",
    "                             ('value', '30.0'),\n",
    "                             ('title', 'Minimum Target Size'),\n",
    "                             ('abstract', 'Minimum Target Size (m): Target with dimension smaller than this threshold is eliminated (Object-Discrimination).'),\n",
    "                             ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Target Size (m)**\n",
    "\n",
    "Maximum Target Size (m): Target with dimension larger than this threshold is eliminated (Object-Discrimination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxTargetSizeInMeter = dict([('id', 'maxTargetSizeInMeter'),\n",
    "                             ('value', '600.0'),\n",
    "                             ('title', 'Maximum Target Size (m)'),\n",
    "                             ('abstract', 'Maximum Target Size (m): Target with dimension larger than this threshold is eliminated (Object-Discrimination).'),\n",
    "                             ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ['S1B_IW_GRDH_1SDV_20170703T194823_20170703T194848_006328_00B202_5554']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_references = ['https://catalog.terradue.com/sentinel1/search?uid=S1B_IW_GRDH_1SDV_20170703T194823_20170703T194848_006328_00B202_5554']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data/S-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import snappy\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from py_snap_helpers import op_help, get_operator_default_parameters, GraphProcessor\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gdal\n",
    "\n",
    "import datetime\n",
    "\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import shapely.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vessel_detection_processing(**kwargs):\n",
    "   \n",
    "    options = dict()\n",
    "    \n",
    "    operators = ['Read',\n",
    "                 'Land-Sea-Mask',\n",
    "                 'Calibration',\n",
    "                 'AdaptiveThresholding',\n",
    "                 'Object-Discrimination',\n",
    "                 'Write']\n",
    "    \n",
    "    for operator in operators:\n",
    "            \n",
    "        print 'Getting default values for Operator {}'.format(operator)\n",
    "        parameters = get_operator_default_parameters(operator)\n",
    "        \n",
    "        options[operator] = parameters\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        \n",
    "        print 'Updating Operator {}'.format(key)\n",
    "        options[key.replace('_', '-')].update(value)\n",
    "    \n",
    "    mygraph = GraphProcessor()\n",
    "    \n",
    "    for index, operator in enumerate(operators):\n",
    "    \n",
    "        print 'Adding Operator {} to graph'.format(operator)\n",
    "        if index == 0:            \n",
    "            source_node_id = ''\n",
    "        \n",
    "        else:\n",
    "            source_node_id = operators[index - 1]\n",
    "        \n",
    "        mygraph.add_node(operator,\n",
    "                         operator, \n",
    "                         options[operator], source_node_id)\n",
    "    \n",
    "    mygraph.view_graph()\n",
    "    \n",
    "    mygraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_folder = ''\n",
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "        \n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operators definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads = []\n",
    "for s1path in input_identifiers:\n",
    "    \n",
    "    read = dict()\n",
    "\n",
    "    s1meta = \"manifest.safe\"\n",
    "    \n",
    "    s1prd = \"%s/%s/%s.SAFE/%s\" % (data_path, s1path, s1path, s1meta)\n",
    "    \n",
    "    read['file'] =  s1prd\n",
    "    #read['formatName'] = 'Sen3_SLSTRL1B_500m'\n",
    "    \n",
    "    reads.append(read)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landseamask = get_operator_default_parameters('Land-Sea-Mask')\n",
    "\n",
    "for p in landseamask:\n",
    "    if p == 'shorelineExtension':\n",
    "        landseamask[p] = shorelineExtension['value']\n",
    "\n",
    "landseamask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = get_operator_default_parameters('Calibration')\n",
    "\n",
    "#for p in LandSeaMask:\n",
    "#    if p == 'shorelineExtension':\n",
    "#        LandSeaMask[p] = '10'\n",
    "\n",
    "calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptivethresholding = get_operator_default_parameters('AdaptiveThresholding')\n",
    "\n",
    "for p in adaptivethresholding:\n",
    "    if p == 'pfa':\n",
    "        adaptivethresholding[p] = pfa['value']\n",
    "\n",
    "adaptivethresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectdiscrimination = get_operator_default_parameters('Object-Discrimination')\n",
    "\n",
    "for p in objectdiscrimination:\n",
    "    if p == 'minTargetSizeInMeter':\n",
    "        objectdiscrimination[p] = minTargetSizeInMeter['value']\n",
    "    elif p == 'maxTargetSizeInMeter':\n",
    "        objectdiscrimination[p] = maxTargetSizeInMeter['value']\n",
    "\n",
    "objectdiscrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writes = []\n",
    "for s1path in input_identifiers:\n",
    "    \n",
    "    write = dict()\n",
    "    \n",
    "    output_path = os.path.join(temp_folder, s1path + '_temp')\n",
    "    \n",
    "    write['file'] = output_path\n",
    "\n",
    "    writes.append(write)\n",
    "writes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r,w in zip(reads,writes):\n",
    "    \n",
    "    vessel_detection_processing(Read=r,\n",
    "                                Land_Sea_Mask=landseamask,\n",
    "                                Calibration=calibration,\n",
    "                                AdaptiveThresholding=adaptivethresholding,\n",
    "                                Object_Discrimination=objectdiscrimination,\n",
    "                                Write=w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detected vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipdetections_path = os.path.join(writes[0]['file'] + '.data', 'vector_data', 'ShipDetections.csv')\n",
    "shipdetections_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipdetections_raw = pd.read_csv(shipdetections_path,sep='\\t', skiprows=[0])\n",
    "shipdetections_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read AIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_data = '/workspace/Better_3rd_phase/Applications/EXT-03-02-01/ewf-ext-03-02-01/src/main/app-resources/notebook/etc/ais_2017_07.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AIS data (first to DataFrame, then convert to GeoDataFrame).\n",
    "ais_df = pd.read_csv(ais_data, decimal=\",\", usecols=['MMSI', 'IMO', 'STATUS', 'SPEED(KNOTS x10)', 'LON', 'LAT',\n",
    "                                                     'COURSE', 'HEADING', 'TIMESTAMP(UTC)'],\n",
    "                     dtype={'LON': float, 'LAT': float})\n",
    "print('Number of rows in %s: %d' % (ais_data.split('\\\\')[-1], len(ais_df.index)))\n",
    "\n",
    "ais_gdf = gpd.GeoDataFrame(ais_df, geometry=gpd.points_from_xy(ais_df.LON, ais_df.LAT), crs=\"EPSG:4326\")\n",
    "ais_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AOI = shapely.wkt.loads('POLYGON ((-29.97968971227660973 39.49718800212976078, -26.71593511606884519 39.49718800212976078, -26.75288328130893234 37.42809074868483776, -29.99200576735664114 37.46503891392492847, -29.97968971227660973 39.49718800212976078))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_gdf_aoi = ais_gdf[ais_gdf['geometry'].within(AOI)]\n",
    "ais_gdf_aoi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporary folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"license\">License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
