{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ewf-ext-03-02-01 - SeaEyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"quicklink\">Quick link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Objective](#objective)\n",
    "* [Data](#data)\n",
    "* [Service Definition](#service)\n",
    "* [Parameter Definition](#parameter)\n",
    "* [Runtime Parameter Definition](#runtime)\n",
    "* [Workflow](#workflow)\n",
    "* [License](#license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"objective\">Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"data\">Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ewf-ext-03-02-01 - SeaEyes'),\n",
    "                ('abstract', 'ewf-ext-03-02-01 - SeaEyes'),\n",
    "                ('id', 'ewf-ext-03-02-01')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background Window Size**\n",
    "\n",
    "Background Window Size: The window size in pixels for computing local mean backscatter level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backgroundWindowSize = dict([('id', 'backgroundWindowSize'),\n",
    "                             ('value', '181'),\n",
    "                             ('title', 'Background Window Size'),\n",
    "                             ('abstract', 'Background Window Size: The window size in pixels for computing local mean backscatter level.'),\n",
    "                             ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Threshold Shift**\n",
    "\n",
    "Threshold Shift (dB): The detecting threshold is lower than the local mean backscatter level by this amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholdShift = dict([('id', 'thresholdShift'),\n",
    "                       ('value', '2.0'),\n",
    "                       ('title', 'Threshold Shift'),\n",
    "                       ('abstract', 'Threshold Shift (dB): The detecting threshold is lower than the local mean backscatter level by this amount.'),\n",
    "                       ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimum Cluster Size**\n",
    "\n",
    "The minimum cluster size in square kilometer. Cluster with size smaller than this size is eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minClusterSizeInKm2 = dict([('id', 'minClusterSizeInKm2'),\n",
    "                            ('value', '0.1'),\n",
    "                            ('title', 'Minimum Cluster Size'),\n",
    "                            ('abstract', 'The minimum cluster size in square kilometer. Cluster with size smaller than this size is eliminated.'),\n",
    "                            ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Region Of Interest**\n",
    "\n",
    "WKT Polygon for the Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((-54.3452413212612 69.74156437889997, -51.65178350038967 69.98563658328254, -52.514956886601865 71.11255404659198, -55.35237767944321 70.857913012771, -54.3452413212612 69.74156437889997))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifier = 'S1B_IW_GRDH_1SDV_20170703T194823_20170703T194848_006328_00B202_5554'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_reference = 'https://catalog.terradue.com/sentinel1/search?uid=S1B_IW_GRDH_1SDV_20170703T194823_20170703T194848_006328_00B202_5554'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data/S-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import snappy\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from py_snap_helpers import op_help, get_operator_default_parameters, GraphProcessor\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gdal\n",
    "\n",
    "import datetime\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vessel_detection_processing(**kwargs):\n",
    "   \n",
    "    options = dict()\n",
    "    \n",
    "    operators = ['Read',\n",
    "                 'Land-Sea-Mask',\n",
    "                 'Calibration',\n",
    "                 'AdaptiveThresholding',\n",
    "                 'Object-Discrimination',\n",
    "                 'Write']\n",
    "    \n",
    "    for operator in operators:\n",
    "            \n",
    "        print 'Getting default values for Operator {}'.format(operator)\n",
    "        parameters = get_operator_default_parameters(operator)\n",
    "        \n",
    "        options[operator] = parameters\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        \n",
    "        print 'Updating Operator {}'.format(key)\n",
    "        options[key.replace('_', '-')].update(value)\n",
    "    \n",
    "    mygraph = GraphProcessor()\n",
    "    \n",
    "    for index, operator in enumerate(operators):\n",
    "    \n",
    "        print 'Adding Operator {} to graph'.format(operator)\n",
    "        if index == 0:            \n",
    "            source_node_id = ''\n",
    "        \n",
    "        else:\n",
    "            source_node_id = operators[index - 1]\n",
    "        \n",
    "        mygraph.add_node(operator,\n",
    "                         operator, \n",
    "                         options[operator], source_node_id)\n",
    "    \n",
    "    mygraph.view_graph()\n",
    "    \n",
    "    mygraph.run()\n",
    "    \n",
    "    \n",
    "    \n",
    "def ellipsoid_correction_processing(**kwargs):\n",
    "   \n",
    "    options = dict()\n",
    "    \n",
    "    operators = ['Read',\n",
    "                 'Ellipsoid-Correction-RD',\n",
    "                 'Write']\n",
    "    \n",
    "    for operator in operators:\n",
    "            \n",
    "        print 'Getting default values for Operator {}'.format(operator)\n",
    "        parameters = get_operator_default_parameters(operator)\n",
    "        \n",
    "        options[operator] = parameters\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        \n",
    "        print 'Updating Operator {}'.format(key)\n",
    "        options[key.replace('_', '-')].update(value)\n",
    "    \n",
    "    mygraph = GraphProcessor()\n",
    "    \n",
    "    for index, operator in enumerate(operators):\n",
    "    \n",
    "        print 'Adding Operator {} to graph'.format(operator)\n",
    "        if index == 0:            \n",
    "            source_node_id = ''\n",
    "        \n",
    "        else:\n",
    "            source_node_id = operators[index - 1]\n",
    "        \n",
    "        mygraph.add_node(operator,\n",
    "                         operator, \n",
    "                         options[operator], source_node_id)\n",
    "    \n",
    "    mygraph.view_graph()\n",
    "    \n",
    "    mygraph.run()\n",
    "    \n",
    "    \n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    \n",
    "    \n",
    "    if mask is not None and mask is not 0:\n",
    "        # TODO: check if output folder exists\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "       \n",
    "    # change color of detected pixels to red\n",
    "    ct = gdal.ColorTable()\n",
    "    ct.SetColorEntry(1, (255,0,0,255))\n",
    "    raster_band.SetColorTable(ct)\n",
    "        \n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    \n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "    \n",
    "def get_formatted_date(datetime_str):\n",
    "    date = datetime.datetime.strftime(datetime_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = datetime.datetime(year=first_date.year, month=first_date.month, day=first_date.day)\n",
    "    first_date = first_date + datetime.timedelta(days=0, hours=0, minutes=0, seconds=0)\n",
    "    first_date = get_formatted_date(first_date)\n",
    "    \n",
    "    last_date = datetime.datetime(year=last_date.year, month=last_date.month, day=last_date.day)\n",
    "    last_date = last_date + datetime.timedelta(days=0, hours=23, minutes=59, seconds=59)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "\n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aux folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_folder = ''\n",
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "        \n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operators definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = dict()\n",
    "\n",
    "s1meta = \"manifest.safe\"\n",
    "\n",
    "\n",
    "input_identifiers = [input_identifier]\n",
    "\n",
    "for s1path in input_identifiers:\n",
    "\n",
    "    s1prd = \"%s/%s/%s.SAFE/%s\" % (data_path, s1path, s1path, s1meta)\n",
    "\n",
    "read['file'] =  s1prd\n",
    "#read['formatName'] = 'Sen3_SLSTRL1B_500m'\n",
    "\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landseamask = get_operator_default_parameters('Land-Sea-Mask')\n",
    "\n",
    "for p in landseamask:\n",
    "    if p == 'shorelineExtension':\n",
    "        LandSeaMask[p] = '10'\n",
    "\n",
    "landseamask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = get_operator_default_parameters('Calibration')\n",
    "\n",
    "#for p in LandSeaMask:\n",
    "#    if p == 'shorelineExtension':\n",
    "#        LandSeaMask[p] = '10'\n",
    "\n",
    "calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptivethresholding = get_operator_default_parameters('AdaptiveThresholding')\n",
    "\n",
    "for p in adaptivethresholding:\n",
    "    if p == 'pfa':\n",
    "        adaptivethresholding[p] = '12.5'\n",
    "\n",
    "adaptivethresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectdiscrimination = get_operator_default_parameters('Object-Discrimination')\n",
    "\n",
    "for p in objectdiscrimination:\n",
    "    if p == 'minTargetSizeInMeter':\n",
    "        objectdiscrimination[p] = '30'\n",
    "\n",
    "objectdiscrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = dict()\n",
    "\n",
    "output_path = os.path.join(temp_folder, 'temp')\n",
    "\n",
    "write['file'] = output_path\n",
    "write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vessel_detection_processing(Read=read,\n",
    "                            Land_Sea_Mask=landseamask,\n",
    "                            Calibration=calibration,\n",
    "                            AdaptiveThresholding=adaptivethresholding,\n",
    "                            Object_Discrimination=objectdiscrimination,\n",
    "                            Write=write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion to WGS84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detected vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = dict()\n",
    "\n",
    "read['file'] =  output_path + '.dim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsoidcorrectionrd = dict()\n",
    "\n",
    "\n",
    "ellipsoidcorrectionrd['sourceBands'] = 'Sigma0_HH_oil_spill_bit_msk'\n",
    "ellipsoidcorrectionrd['sourceBandNames'] = 'Sigma0_HH_oil_spill_bit_msk'\n",
    "\n",
    "#ellipsoidcorrectionrd['sourceBands'] = 'Sigma0_HH'\n",
    "#ellipsoidcorrectionrd['sourceBandNames'] = 'Sigma0_HH'\n",
    "\n",
    "ellipsoidcorrectionrd['demName'] = 'GETASSE30'\n",
    "ellipsoidcorrectionrd['imgResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "\n",
    "proj = '''GEOGCS[\"WGS84(DD)\", DATUM[\"WGS84\", SPHEROID[\"WGS84\", 6378137.0, 298.257223563]], PRIMEM[\"Greenwich\", 0.0], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH]]'''\n",
    "\n",
    "ellipsoidcorrectionrd['mapProjection'] = proj       # comment this line if no need to convert to UTM/WGS84, default is WGS84\n",
    "ellipsoidcorrectionrd['saveSelectedSourceBand'] = 'true'\n",
    "\n",
    "ellipsoidcorrectionrd['nodataValueAtSea'] = 'false'\n",
    "\n",
    "ellipsoidcorrectionrd['pixelSpacingInMeter'] = '25.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = dict()\n",
    "\n",
    "output_path2 = os.path.join(temp_folder, 'temp2.tif')\n",
    "\n",
    "write['file'] = output_path2\n",
    "write['formatName'] = 'GeoTIFF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsoid_correction_processing(Read=read,\n",
    "                                Ellipsoid_Correction_RD=ellipsoidcorrectionrd,\n",
    "                                Write=write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path2 = 'temp2.tif'\n",
    "\n",
    "dataset = gdal.Open(output_path2)\n",
    "\n",
    "product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "projection = dataset.GetProjection()\n",
    "geotransform = dataset.GetGeoTransform()\n",
    "no_data_value = dataset.GetRasterBand(1).GetNoDataValue()\n",
    "data_type = dataset.GetRasterBand(1).DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date in str\n",
    "date_str = input_identifiers[0].split('_')[4].split('T')[0]\n",
    "\n",
    "# date in datetime\n",
    "dt = datetime.datetime.strptime(date_str, \"%Y%m%d\")\n",
    "\n",
    "# output file path\n",
    "output_tiff_path = os.path.join(output_folder, 'oil_sheen_bit_S1_HH_' + date_str + '.tif')\n",
    "\n",
    "# writes final tiff image\n",
    "write_output_image(output_tiff_path, product_array, 'GTiff', 1, mask=None, output_projection=projection, output_geotransform=geotransform, no_data_value=0)\n",
    "\n",
    "# writes properties file\n",
    "write_properties_file(output_tiff_path, dt, dt, aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAR image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = dict()\n",
    "\n",
    "read['file'] =  output_path + '.dim'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsoidcorrectionrd = dict()\n",
    "\n",
    "\n",
    "#ellipsoidcorrectionrd['sourceBands'] = 'Sigma0_HH_oil_spill_bit_msk'\n",
    "#ellipsoidcorrectionrd['sourceBandNames'] = 'Sigma0_HH_oil_spill_bit_msk'\n",
    "\n",
    "ellipsoidcorrectionrd['sourceBands'] = 'Sigma0_HH'\n",
    "ellipsoidcorrectionrd['sourceBandNames'] = 'Sigma0_HH'\n",
    "\n",
    "ellipsoidcorrectionrd['demName'] = 'GETASSE30'\n",
    "ellipsoidcorrectionrd['imgResamplingMethod'] = 'BILINEAR_INTERPOLATION'\n",
    "\n",
    "proj = '''GEOGCS[\"WGS84(DD)\", DATUM[\"WGS84\", SPHEROID[\"WGS84\", 6378137.0, 298.257223563]], PRIMEM[\"Greenwich\", 0.0], UNIT[\"degree\", 0.017453292519943295], AXIS[\"Geodetic longitude\", EAST], AXIS[\"Geodetic latitude\", NORTH]]'''\n",
    "\n",
    "ellipsoidcorrectionrd['mapProjection'] = proj       # comment this line if no need to convert to UTM/WGS84, default is WGS84\n",
    "ellipsoidcorrectionrd['saveSelectedSourceBand'] = 'true'\n",
    "\n",
    "ellipsoidcorrectionrd['nodataValueAtSea'] = 'false'\n",
    "\n",
    "ellipsoidcorrectionrd['pixelSpacingInMeter'] = '25.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = dict()\n",
    "\n",
    "\n",
    "#output_path2 = os.path.join(output_folder, 'Sigma0_HH_' + date_str + '.tif')\n",
    "output_path2 = os.path.join(temp_folder, 'Sigma0_HH_' + date_str + '.tif')\n",
    "\n",
    "write['file'] = output_path2\n",
    "write['formatName'] = 'GeoTIFF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipsoid_correction_processing(Read=read,\n",
    "                                Ellipsoid_Correction_RD=ellipsoidcorrectionrd,\n",
    "                                Write=write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file path\n",
    "output_tiff_path2 = os.path.join(output_folder, 'Sigma0_HH_' + date_str + '.tif')\n",
    "\n",
    "ds = gdal.Open(output_path2)\n",
    "\n",
    "product_array = ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "vmin = np.percentile(product_array[product_array > 0], 5)\n",
    "vmax = np.percentile(product_array[product_array > 0], 95)\n",
    "\n",
    "scaleParams = [[vmin, vmax, 0, 255]]\n",
    "\n",
    "ds = gdal.Translate(output_tiff_path2, ds, outputType = gdal.GDT_Byte, scaleParams=scaleParams)\n",
    "ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes properties file\n",
    "write_properties_file(output_tiff_path2, dt, dt, aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporary folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"license\">License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
